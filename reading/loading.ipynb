{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Steps\n",
    "\n",
    "## Bourso \n",
    "- read raw bousoramra\n",
    "- clean raw bousorama\n",
    "- make a subsets with only unique : symbol + name combination\n",
    "- make the mapping of market and the cleaning of symnbol\n",
    "\n",
    "## Euronext\n",
    "- read raw euronext\n",
    "- clean raw euronext\n",
    "- make a subsets with only unique : Name + ISIN + Symbol + Market combination\n",
    "- make the mapping of market via the 'Market' column\n",
    "\n",
    "## Join\n",
    "- join by unique combination of Symbol + Market ID ?\n",
    "- join stuff via other techniques\n",
    "- apply the mapping to the full db bousorama + euronext cleaned\n",
    "\n",
    "## Import DB\n",
    "- Import companies table\n",
    "- Import stocks table\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import dateutil\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import requests\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boursorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_bousorama(year):\n",
    "    compA = pd.concat({dateutil.parser.parse(f.split('compA ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('/Users/titouanverhille/Developer/pybd-project/reading/bourso/' + year + '/compA*')})\n",
    "    compB = pd.concat({dateutil.parser.parse(f.split('compB ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('/Users/titouanverhille/Developer/pybd-project/reading/bourso/' + year + '/compB*')})\n",
    "    merge = pd.concat([compA, compB])\n",
    "    return merge\n",
    "\n",
    "def clean_raw_bousorama(df):\n",
    "    return df\n",
    "\n",
    "def make_subset_of_companies_bousorama(df):\n",
    "    # make a copy of whole datframe that contains only the unique combination of symbol + name and only those columns\n",
    "    df_unique = df[['symbol', 'name']].drop_duplicates(subset=['symbol', 'name']).reset_index(drop=True)\n",
    "    return df_unique\n",
    "\n",
    "def add_market_column_boursorama(df):\n",
    "    # add a column 'Market' to the df_unique and cleaned symbol\n",
    "    initial_markets_data = (\n",
    "        (1, \"New York\", \"nyse\", \"\", \"NYSE\", \"\"),\n",
    "        (2, \"London Stock Exchange\", \"lse\", \"1u*.L\", \"LSE\", \"\"),\n",
    "        (3, \"Bourse de Milan\", \"milano\", \"1g\", \"\", \"\"),\n",
    "        (4, \"Mercados Espanoles\", \"mercados\", \"FF55-\", \"\", \"\"),\n",
    "        (5, \"Amsterdam\", \"amsterdam\", \"1rA\", \"\", \"Amsterdam\"),\n",
    "        (6, \"Paris\", \"paris\", \"1rP\", \"ENXTPA\", \"Paris\"),\n",
    "        (7, \"Deutsche Borse\", \"xetra\", \"1z\", \"\", \"\"),\n",
    "        (8, \"Bruxelle\", \"bruxelle\", \"FF11_\", \"\", \"Brussels\"),\n",
    "        (9, \"Australie\", \"asx\", \"\", \"ASX\", \"\"),\n",
    "        (100, \"International\", \"int\", \"\", \"\", \"\"),  # should be last one\n",
    "    )\n",
    "    df['market'] = df['symbol'].apply(lambda x: next(\n",
    "        (market[1] for market in initial_markets_data \n",
    "         if market[3] and market[3] in x),\n",
    "        \"International\"  # Default value if no match found\n",
    "    ))\n",
    "    \n",
    "    # Add cleaned symbol column by removing market prefixes\n",
    "    df['cleaned_symbol'] = df['symbol'].apply(lambda x: next(\n",
    "        (x.replace(market[3], '') for market in initial_markets_data \n",
    "         if market[3] and market[3] in x),\n",
    "        x  # Keep original if no prefix found\n",
    "    ))\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_normalized_dataframe_boursorama(df):\n",
    "    # Columns should be : symbol, name, market \n",
    "    # rename cleaned_symbol to symbol\n",
    "    df.drop(columns=['symbol'], inplace=True)\n",
    "    df.rename(columns={'cleaned_symbol': 'symbol'}, inplace=True)\n",
    "    return df[['symbol', 'name', 'market']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021'\n",
    "\n",
    "raw_boursorama = read_raw_bousorama(year)\n",
    "raw_boursorama = clean_raw_bousorama(raw_boursorama)\n",
    "companies_bousorama = make_subset_of_companies_bousorama(raw_boursorama)\n",
    "companies_bousorama = add_market_column_boursorama(companies_bousorama)\n",
    "companies_bousorama = make_normalized_dataframe_boursorama(companies_bousorama)\n",
    "companies_bousorama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euronext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_euronext(year):\n",
    "    # raw columns name are\n",
    "    # Name,ISIN,Symbol,\tMarket,\tTrading, Currency, Open, High, Low, Last, Last Date/Time, Time Zone, Volume, Turnover\n",
    "    def read_euronext_file(path):\n",
    "        if path.endswith(\".csv\"):\n",
    "            return pd.read_csv(path, delimiter='\\t')\n",
    "        return pd.read_excel(path)\n",
    "\n",
    "    files = glob.glob('/Users/titouanverhille/Developer/pybd-project/reading/euronext/*' + year + '*')\n",
    "    df =  pd.concat([read_euronext_file(f) for f in files])\n",
    "    return df\n",
    "\n",
    "def clean_raw_euronext(df):\n",
    "    df = df.iloc[3:]\n",
    "    df = df[df['Symbol'].notna()]\n",
    "    return df\n",
    "\n",
    "def make_subset_of_companies_euronext(df):\n",
    "    # make a copy of whole datframe that contains only the unique combination of Name\tISIN\tSymbol\tMarket and only those columns\n",
    "    df_unique = df[['Name', 'ISIN', 'Symbol', 'Market']].drop_duplicates(subset=[\n",
    "        'Name',\n",
    "        'ISIN', \n",
    "        'Symbol',\n",
    "        'Market'\n",
    "    ])\n",
    "    return df_unique.copy()\n",
    "\n",
    "def add_market_column_euronext(df):\n",
    "    # add a column 'Market' to the df_unique\n",
    "    euronext_market_to_db_market = {\n",
    "        \"Euronext Growth Paris\":\"Paris\",\n",
    "        \"Euronext Paris\":\"Paris\",\n",
    "        \"Euronext Access Paris\":\"Paris\",\n",
    "        \"Euronext Paris, Amsterdam\":\"Paris\",\n",
    "        \"Euronext Paris, Brussels\":\"Paris\",\n",
    "        \"Euronext Amsterdam, Brussels, Paris\":\"Paris\",\n",
    "        \"Euronext Amsterdam, Paris\":\"Paris\",\n",
    "        \"Euronext Brussels, Paris\":\"Paris\",\n",
    "        \"Euronext Growth Paris, Brussels\":\"Paris\",\n",
    "        \"Euronext Paris, Amsterdam, Brussels\":\"Paris\",\n",
    "        \"Euronext Growth Dublin\":\"Dublin\",\n",
    "        \"Euronext Dublin\":\"Dublin\",\n",
    "    }\n",
    "    df['market'] = df['Market'].map(euronext_market_to_db_market)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_normalized_dataframe_euronext(df):\n",
    "    # Columns should be : symbol, name, market and isin\n",
    "    df.rename(columns={'Symbol': 'symbol'}, inplace=True)\n",
    "    df.rename(columns={'ISIN': 'isin'}, inplace=True)\n",
    "    df.rename(columns={'Name': 'name'}, inplace=True)\n",
    "    return df[['symbol', 'name', 'market', 'isin']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021'\n",
    "\n",
    "raw_euronext = read_raw_euronext(year)\n",
    "raw_euronext = clean_raw_euronext(raw_euronext)\n",
    "companies_euronext = make_subset_of_companies_euronext(raw_euronext)\n",
    "companies_euronext = add_market_column_euronext(companies_euronext)\n",
    "companies_euronext = make_normalized_dataframe_euronext(companies_euronext)\n",
    "companies_euronext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames based on symbol + name + market\n",
    "merged_companies = pd.merge(companies_euronext, companies_bousorama, \n",
    "                            left_on=['symbol', 'name', 'market'], \n",
    "                            right_on=['symbol', 'name', 'market'], \n",
    "                            how='outer')\n",
    "\n",
    "print(\"original length bourso : \", len(companies_bousorama))\n",
    "print(\"original length euronext : \", len(companies_euronext))\n",
    "print(\"original length combined : \", len(companies_bousorama) + len(companies_euronext))\n",
    "print(\"merged length : \", len(merged_companies))\n",
    "\n",
    "merged_companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_companies[merged_companies['name'].str.contains(\"ACCOR\")]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
