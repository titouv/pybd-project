{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Steps\n",
    "\n",
    "## Bourso \n",
    "- read raw bousoramra\n",
    "- clean raw bousorama\n",
    "- make a subsets with only unique : symbol + name combination\n",
    "- make the mapping of market and the cleaning of symnbol\n",
    "\n",
    "## Euronext\n",
    "- read raw euronext\n",
    "- clean raw euronext\n",
    "- make a subsets with only unique : Name + ISIN + Symbol + Market combination\n",
    "- make the mapping of market via the 'Market' column\n",
    "\n",
    "## Join\n",
    "- join by unique combination of Symbol + Market ID ?\n",
    "- join stuff via other techniques\n",
    "- apply the mapping to the full db bousorama + euronext cleaned\n",
    "\n",
    "## Import DB\n",
    "- Import companies table\n",
    "- Import stocks table\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import dateutil\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import requests\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boursorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_bousorama(year):\n",
    "    compA = pd.concat({dateutil.parser.parse(f.split('compA ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('/Users/titouanverhille/Developer/pybd-project/reading/bourso/' + year + '/compA*')})\n",
    "    compB = pd.concat({dateutil.parser.parse(f.split('compB ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('/Users/titouanverhille/Developer/pybd-project/reading/bourso/' + year + '/compB*')})\n",
    "    merge = pd.concat([compA, compB])\n",
    "    return merge\n",
    "\n",
    "def clean_raw_bousorama(df):\n",
    "    return df\n",
    "\n",
    "def make_subset_of_companies_bousorama(df):\n",
    "    # make a copy of whole datframe that contains only the unique combination of symbol + name and only those columns\n",
    "    df_unique = df[['symbol', 'name']].drop_duplicates(subset=['symbol', 'name']).reset_index(drop=True)\n",
    "    return df_unique\n",
    "\n",
    "def add_market_column_boursorama(df):\n",
    "    # add a column 'Market' to the df_unique and cleaned symbol\n",
    "    initial_markets_data = (\n",
    "        (1, \"New York\", \"nyse\", \"\", \"NYSE\", \"\"),\n",
    "        (2, \"London Stock Exchange\", \"lse\", \"1u*.L\", \"LSE\", \"\"),\n",
    "        (3, \"Bourse de Milan\", \"milano\", \"1g\", \"\", \"\"),\n",
    "        (4, \"Mercados Espanoles\", \"mercados\", \"FF55-\", \"\", \"\"),\n",
    "        (5, \"Amsterdam\", \"amsterdam\", \"1rA\", \"\", \"Amsterdam\"),\n",
    "        (6, \"Paris\", \"paris\", \"1rP\", \"ENXTPA\", \"Paris\"),\n",
    "        (7, \"Deutsche Borse\", \"xetra\", \"1z\", \"\", \"\"),\n",
    "        (8, \"Bruxelle\", \"bruxelle\", \"FF11_\", \"\", \"Brussels\"),\n",
    "        (9, \"Australie\", \"asx\", \"\", \"ASX\", \"\"),\n",
    "        (100, \"International\", \"int\", \"\", \"\", \"\"),  # should be last one\n",
    "    )\n",
    "    df['market'] = df['symbol'].apply(lambda x: next(\n",
    "        (market[1] for market in initial_markets_data \n",
    "         if market[3] and market[3] in x),\n",
    "        \"International\"  # Default value if no match found\n",
    "    ))\n",
    "    \n",
    "    # Add cleaned symbol column by removing market prefixes\n",
    "    df['cleaned_symbol'] = df['symbol'].apply(lambda x: next(\n",
    "        (x.replace(market[3], '') for market in initial_markets_data \n",
    "         if market[3] and market[3] in x),\n",
    "        x  # Keep original if no prefix found\n",
    "    ))\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_normalized_dataframe_boursorama(df):\n",
    "    # Columns should be : symbol, name, market and boursorama (for the raw value)\n",
    "    # rename cleaned_symbol to symbol\n",
    "    df.rename(columns={'symbol':'boursorama'}, inplace=True)\n",
    "    df.rename(columns={'cleaned_symbol': 'symbol'}, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021'\n",
    "\n",
    "raw_boursorama = read_raw_bousorama(year)\n",
    "raw_boursorama = clean_raw_bousorama(raw_boursorama)\n",
    "companies_bousorama = make_subset_of_companies_bousorama(raw_boursorama)\n",
    "companies_bousorama = add_market_column_boursorama(companies_bousorama)\n",
    "companies_bousorama = make_normalized_dataframe_boursorama(companies_bousorama)\n",
    "companies_bousorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_boursorama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euronext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_euronext(year):\n",
    "    # raw columns name are\n",
    "    # Name,ISIN,Symbol,\tMarket,\tTrading, Currency, Open, High, Low, Last, Last Date/Time, Time Zone, Volume, Turnover\n",
    "    def read_euronext_file(path):\n",
    "        if path.endswith(\".csv\"):\n",
    "            return pd.read_csv(path, delimiter='\\t')\n",
    "        return pd.read_excel(path)\n",
    "\n",
    "    files = glob.glob('/Users/titouanverhille/Developer/pybd-project/reading/euronext/*' + year + '*')\n",
    "    df =  pd.concat([read_euronext_file(f) for f in files])\n",
    "    return df\n",
    "\n",
    "def clean_raw_euronext(df):\n",
    "    df = df.iloc[3:]\n",
    "    df = df[df['Symbol'].notna()]\n",
    "    return df\n",
    "\n",
    "def make_subset_of_companies_euronext(df):\n",
    "    # make a copy of whole datframe that contains only the unique combination of Name\tISIN\tSymbol\tMarket and only those columns\n",
    "    df_unique = df[['Name', 'ISIN', 'Symbol', 'Market']].drop_duplicates(subset=[\n",
    "        'Name',\n",
    "        'ISIN', \n",
    "        'Symbol',\n",
    "        'Market'\n",
    "    ])\n",
    "    return df_unique.copy()\n",
    "\n",
    "def add_market_column_euronext(df):\n",
    "    # add a column 'Market' to the df_unique\n",
    "    euronext_market_to_db_market = {\n",
    "        \"Euronext Growth Paris\":\"Paris\",\n",
    "        \"Euronext Paris\":\"Paris\",\n",
    "        \"Euronext Access Paris\":\"Paris\",\n",
    "        \"Euronext Paris, Amsterdam\":\"Paris\",\n",
    "        \"Euronext Paris, Brussels\":\"Paris\",\n",
    "        \"Euronext Amsterdam, Brussels, Paris\":\"Paris\",\n",
    "        \"Euronext Amsterdam, Paris\":\"Paris\",\n",
    "        \"Euronext Brussels, Paris\":\"Paris\",\n",
    "        \"Euronext Growth Paris, Brussels\":\"Paris\",\n",
    "        \"Euronext Paris, Amsterdam, Brussels\":\"Paris\",\n",
    "        \"Euronext Growth Dublin\":\"Dublin\",\n",
    "        \"Euronext Dublin\":\"Dublin\",\n",
    "    }\n",
    "    df['market'] = df['Market'].map(euronext_market_to_db_market)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_normalized_dataframe_euronext(df):\n",
    "    # Columns should be : symbol, name, market and isin\n",
    "    df.rename(columns={'Symbol': 'symbol'}, inplace=True)\n",
    "    df.rename(columns={'ISIN': 'isin'}, inplace=True)\n",
    "    df.rename(columns={'Name': 'name'}, inplace=True)\n",
    "    # add column euronext with the raw name\n",
    "    df['euronext'] = df['name']\n",
    "    return df[['symbol', 'name', 'market', 'isin', 'euronext']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021'\n",
    "\n",
    "raw_euronext = read_raw_euronext(year)\n",
    "raw_euronext = clean_raw_euronext(raw_euronext)\n",
    "companies_euronext = make_subset_of_companies_euronext(raw_euronext)\n",
    "companies_euronext = add_market_column_euronext(companies_euronext)\n",
    "companies_euronext = make_normalized_dataframe_euronext(companies_euronext)\n",
    "companies_euronext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_euronext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames based on symbol + name + market\n",
    "merged_companies = pd.merge(companies_euronext, companies_bousorama, \n",
    "                            left_on=['symbol', 'name', 'market'], \n",
    "                            right_on=['symbol', 'name', 'market'], \n",
    "                            suffixes=('_euronext', '_boursorama'),\n",
    "                            how='outer')\n",
    "\n",
    "print(\"original length bourso : \", len(companies_bousorama))\n",
    "print(\"original length euronext : \", len(companies_euronext))\n",
    "print(\"original length combined : \", len(companies_bousorama) + len(companies_euronext))\n",
    "print(\"merged length : \", len(merged_companies))\n",
    "\n",
    "merged_companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_companies[merged_companies['name'].str.contains(\"ACCOR\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_db_dataframe = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"id\", \"name\", \"mid\", \"symbol\", \"isin\", \"boursorama\", \"euronext\", \n",
    "        # not used, ricou explains why in moodle question\n",
    "        # \"pea\", \"sector1\", \"sector2\", \"sector3\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "initial_markets_data = (\n",
    "    (1, \"New York\", \"nyse\", \"\", \"NYSE\", \"\"),\n",
    "    (2, \"London Stock Exchange\", \"lse\", \"1u*.L\", \"LSE\", \"\"),\n",
    "    (3, \"Bourse de Milan\", \"milano\", \"1g\", \"\", \"\"),\n",
    "    (4, \"Mercados Espanoles\", \"mercados\", \"FF55-\", \"\", \"\"),\n",
    "    (5, \"Amsterdam\", \"amsterdam\", \"1rA\", \"\", \"Amsterdam\"),\n",
    "    (6, \"Paris\", \"paris\", \"1rP\", \"ENXTPA\", \"Paris\"),\n",
    "    (7, \"Deutsche Borse\", \"xetra\", \"1z\", \"\", \"\"),\n",
    "    (8, \"Bruxelle\", \"bruxelle\", \"FF11_\", \"\", \"Brussels\"),\n",
    "    (9, \"Australie\", \"asx\", \"\", \"ASX\", \"\"),\n",
    "    (100, \"International\", \"int\", \"\", \"\", \"\"),  # should be last one\n",
    ")\n",
    "# generate id\n",
    "companies_db_dataframe['id'] = merged_companies.index\n",
    "companies_db_dataframe['name'] = merged_companies['name']\n",
    "# adapt from name (2 columns) to mid (1 column)\n",
    "companies_db_dataframe['mid'] = merged_companies['market'].apply(lambda x: next(\n",
    "    (market[1] for market in initial_markets_data \n",
    "        if market[3] and market[3] in x),\n",
    "    \"100\"  # Default value if no match found\n",
    "))\n",
    "companies_db_dataframe['symbol'] = merged_companies['symbol']\n",
    "companies_db_dataframe['isin'] = merged_companies['isin']\n",
    "# TODO see to fill column boursorama and euronext\n",
    "companies_db_dataframe['boursorama'] = merged_companies['boursorama']\n",
    "companies_db_dataframe['euronext'] = merged_companies['euronext']\n",
    "\n",
    "\n",
    "companies_db_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_boursorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column company_id into raw_boursorama and raw_euronext\n",
    "# we use maps for optmized performance\n",
    "\n",
    "bousorama_to_id = dict(zip(companies_db_dataframe['boursorama'], companies_db_dataframe['id']))\n",
    "raw_boursorama['company_id'] = raw_boursorama['symbol'].map(bousorama_to_id)\n",
    "\n",
    "euronext_to_id = dict(zip(companies_db_dataframe['euronext'], companies_db_dataframe['id']))\n",
    "raw_euronext['company_id'] = raw_euronext['Name'].map(euronext_to_id)\n",
    "\n",
    "raw_euronext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_euronext[raw_euronext['Last Date/Time'] == '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create daystocks for euronext\n",
    "daystocks_db_dataframe = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"date\", \"cid\", \"open\", \"close\", \"high\", \"low\", \"volume\", \"mean\", \"std\"\n",
    "    ],\n",
    ")\n",
    "daystocks_db_dataframe['raw_date'] = raw_euronext['Last Date/Time']\n",
    "daystocks_db_dataframe['date'] = pd.to_datetime(raw_euronext['Last Date/Time'], \n",
    "                                                format='%d/%m/%y %H:%M',\n",
    "                                                errors='coerce')\n",
    "daystocks_db_dataframe['cid'] = raw_euronext['company_id']\n",
    "\n",
    "# Convert columns to numeric, replacing invalid values with NaN\n",
    "daystocks_db_dataframe['open'] = pd.to_numeric(raw_euronext['Open'], errors='coerce')\n",
    "daystocks_db_dataframe['close'] = pd.to_numeric(raw_euronext['Last'], errors='coerce')\n",
    "daystocks_db_dataframe['high'] = pd.to_numeric(raw_euronext['High'], errors='coerce')\n",
    "daystocks_db_dataframe['low'] = pd.to_numeric(raw_euronext['Low'], errors='coerce')\n",
    "daystocks_db_dataframe['volume'] = pd.to_numeric(raw_euronext['Volume'], errors='coerce')\n",
    "# TODO compute mean and std\n",
    "\n",
    "\n",
    "# select when date is nan\n",
    "daystocks_db_dataframe[daystocks_db_dataframe['date'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_euronext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
