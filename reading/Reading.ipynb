{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import dateutil\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import requests\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p bourso/\n",
    "!rm -rf bourso/20*\n",
    "stream = requests.get('https://www.lrde.epita.fr/~ricou/pybd/projet/bourso.tgz', stream=True)\n",
    "tarfile.open(fileobj=stream.raw, mode='r|gz').extractall('bourso/') # try 'r:gz' if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_last(df):\n",
    "    \"\"\" last is of object type and sometimes ends with (c) or (s)\"\"\"\n",
    "    return [float(re.split('\\\\(.\\\\)$',str(x))[0].replace(' ','').replace(',','.')) for x in df[\"last\"]]\n",
    "\n",
    "def read_bourso_year(year):\n",
    "    compA = pd.concat({dateutil.parser.parse(f.split('compA ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('bourso/' + year + '/compA*')})\n",
    "    compB = pd.concat({dateutil.parser.parse(f.split('compB ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('bourso/' + year + '/compB*')})\n",
    "    merge = pd.concat([compA, compB])\n",
    "    merge['last'] = clean_last(merge)\n",
    "    merge.reset_index(level=1, drop=True, inplace=True)\n",
    "    merge.rename_axis('date', axis=0, inplace=True)\n",
    "    #dropping duplicates only checks columns\n",
    "    merge = merge.reset_index().drop_duplicates().set_index('date')\n",
    "    merge.set_index('symbol', append=True, inplace=True)\n",
    "    merge = merge.swaplevel(0,1).sort_index()\n",
    "    \n",
    "    #delta indicates the volume(number of stock sold) per entry instead of volume which is cumulative per day\n",
    "    merge['delta'] = np.zeros(len(merge))\n",
    "    for stock in merge.index.levels[0]:\n",
    "        merge.loc[(stock, slice(None)), 'delta'] =  merge.loc[(stock, slice(None)) ,'volume'].diff()\n",
    "    \n",
    "    #filling holes from start of day data and missing data\n",
    "    merge.loc[merge.delta < 0, 'delta'] = 0\n",
    "    merge.delta = merge.delta.fillna(0)\n",
    "\n",
    "    #sets the delta of the first entry to its volume instead of 0\n",
    "    #we should do this but it fails on 2020 and 2023 so it's disabled for now\n",
    "    #merge.loc[merge.groupby('symbol').head(1).index, 'delta'] = merge.groupby('symbol')['volume'].transform('first')\n",
    "\n",
    "    return merge\n",
    "\n",
    "#test = read_bourso_year('2020')\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bourso_daily(df):\n",
    "    df['turnover'] = df['last'] * df['delta']\n",
    "\n",
    "    dates = df.index.get_level_values('date').normalize()\n",
    "    dates.name = 'date'\n",
    "\n",
    "    df_daily = df.groupby(['symbol', dates]).agg({\n",
    "        'last': 'last',      # Last entry of the day\n",
    "        'volume': 'max',     # Maximum volume of the day\n",
    "        'name': 'first',     # First name entry of the day\n",
    "        'turnover': 'sum'    # Sum of all turnovers in that day\n",
    "    })\n",
    "    return df_daily\n",
    "\n",
    "#tmp = convert_bourso_daily(test)\n",
    "#tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euronext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p euronext/\n",
    "!rm -rf euronext/\n",
    "stream = requests.get('https://www.lrde.epita.fr/~ricou/pybd/projet/euronext.tgz', stream=True)\n",
    "tarfile.open(fileobj=stream.raw, mode='r|gz').extractall('euronext/') # try 'r:gz' if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting at some point in 2022 the column names were changed\n",
    "import dateutil.parser\n",
    "\n",
    "\n",
    "rename_dict = {\n",
    "    \"Open Price\": \"Open\",\n",
    "    \"High Price\": \"High\",\n",
    "    \"low Price\": \"Low\",\n",
    "    \"last Price\": \"Last\",\n",
    "    \"last Trade MIC Time\":\"Last Date/Time\",\n",
    "    \"Currency\":\"Trading Currency\"\n",
    "}\n",
    "\n",
    "#note that some entries in open, high, low, last are just set to -\n",
    "#ok apparently the currency can be set as 0\n",
    "\n",
    "def read_euronext_file(path):\n",
    "    if path.endswith(\".csv\"):\n",
    "        return pd.read_csv(path, delimiter='\\t')\n",
    "    return pd.read_excel(path)\n",
    "\n",
    "def regularize_data_to_numbers(df):\n",
    "    \"\"\" last is of object type and sometimes ends with (c) or (s)\"\"\"\n",
    "    df[['Volume','Turnover']] = df[['Volume','Turnover']].replace('-',0).fillna(0)\n",
    "    df['Last'] = [round(float(x),2) for x in df[\"Last\"]]\n",
    "    df['Volume'] = [int(x) for x in df[\"Volume\"]]\n",
    "    df['Turnover'] = [round(float(x),2) for x in df[\"Turnover\"]]\n",
    "    return df\n",
    "\n",
    "def regularize_euronext_empty_columns_fill(df):\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "    if 'Closing Price' in df.columns:\n",
    "        df['Last'] = df['Last'].fillna(df['Closing Price']).fillna(0)\n",
    "        df.drop(columns=['Closing Price'], inplace=True)\n",
    "    if 'Closing Price DateTime' in df.columns:\n",
    "        df['Last Date/Time'] = df['Last Date/Time'].fillna(df['Closing Price DateTime']).fillna(0)\n",
    "        df.drop(columns=['Closing Price DateTime'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def regularize_data_to_string(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "def convert_foreign_currencies_to_eur(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Normalize currency column\n",
    "    df['Trading Currency'] = df['Trading Currency'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # USD case\n",
    "    usd_mask = df['Trading Currency'] == 'USD'\n",
    "    if usd_mask.any():\n",
    "        print(f\"🔁 Converting {usd_mask.sum()} rows from USD to EUR at rate 0.91\")\n",
    "        df.loc[usd_mask, 'Last'] = df.loc[usd_mask, 'Last'] * 0.91\n",
    "    \n",
    "    # GBP case\n",
    "    gbp_mask = df['Trading Currency'] == 'GBP'\n",
    "    if gbp_mask.any():\n",
    "        print(f\"🔁 Converting {gbp_mask.sum()} rows from GBP to EUR at rate 1.15\")\n",
    "        df.loc[gbp_mask, 'Last'] = df.loc[gbp_mask, 'Last'] * 1.15\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_euronext_year(year):\n",
    "    eur = pd.concat([regularize_euronext_empty_columns_fill(read_euronext_file(f)) for f in glob.glob('euronext/*' + year + '*')])\n",
    "    #the first three rows are a preamble that doesnt give us anything\n",
    "    eur = eur.iloc[3:].reset_index(drop=True)\n",
    "    eur = eur[~((eur['Last'] == '-') & (eur['Volume'] == '-') & (eur['Turnover'] == '-'))]\n",
    "    eur = eur[~((eur['Symbol'].isna()))]\n",
    "    #any remaining '-' in the data we assume to be null or 0\n",
    "    eur = regularize_data_to_numbers(eur)\n",
    "    eur = convert_foreign_currencies_to_eur(eur)\n",
    "    eur = eur.drop_duplicates()\n",
    "    return eur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note Hammerson plc and t stamp inc is in gbp and usd respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that volume in euronext is equivalent to delta in bourso\n",
    "def get_bourso_matching_df(euronext_df):\n",
    "    tmp = euronext_df[['Symbol', 'Last Date/Time', 'ISIN', 'Last', 'Volume', 'Name', 'Turnover']]\n",
    "    tmp = tmp.rename(columns={'Symbol':'symbol', 'Last Date/Time':'date', 'ISIN':'isin', 'Last':'last', 'Volume':'volume', 'Name':'name', 'Turnover':'turnover'})\n",
    "    tmp = tmp.set_index(['symbol','date'])\n",
    "    tmp = tmp.sort_index()\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in boursorama the name is 'AIR FRANCE -KLM' and in euronext it's 'AIR FRANCE - KLM' so i'm just going to remove all of the spaces so we can match up the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 55485 rows had no matching ISIN.\n"
     ]
    }
   ],
   "source": [
    "def get_unique_isin_name_combinations(df):\n",
    "    cleaned = df.copy()\n",
    "    cleaned['isin'] = cleaned['isin'].astype(str).str.strip()\n",
    "    cleaned['name'] = cleaned['name'].astype(str).str.strip().str.lower()\n",
    "    return cleaned[['isin', 'name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "def remove_substrings(series: pd.Series, substrings: list[str]) -> pd.Series:\n",
    "    cleaned = series.astype(str)\n",
    "    for sub in substrings:\n",
    "        cleaned = cleaned.str.replace(sub, '', regex=False)\n",
    "    return cleaned.str.lower()\n",
    "\n",
    "def remove_ending_substrings(series: pd.Series, endings: list[str]) -> pd.Series:\n",
    "    cleaned = series.astype(str)\n",
    "    for ending in endings:\n",
    "        cleaned = cleaned.str.rstrip()  # In case of trailing spaces before matching\n",
    "        cleaned = cleaned.apply(lambda x: x[:-len(ending)] if x.endswith(ending) else x)\n",
    "    return cleaned.str.strip()\n",
    "\n",
    "def remove_starting_substrings(series: pd.Series, prefixes: list[str]) -> pd.Series:\n",
    "    cleaned = series.astype(str)\n",
    "    for prefix in prefixes:\n",
    "        cleaned = cleaned.str.lstrip()  # In case of leading spaces before matching\n",
    "        cleaned = cleaned.apply(lambda x: x[len(prefix):] if x.startswith(prefix) else x)\n",
    "    return cleaned.str.strip()\n",
    "\n",
    "def remove_ending_substrings_regex(series: pd.Series, endings: list[str]) -> pd.Series:\n",
    "    # Escape any special regex characters in endings to match them literally\n",
    "    escaped_endings = [re.escape(e) for e in endings]\n",
    "    \n",
    "    # Build one regex pattern that matches any ending at the end of a string ($)\n",
    "    pattern = f\"({'|'.join(escaped_endings)})$\"\n",
    "    \n",
    "    # Use str.replace with regex=True to remove matching suffixes\n",
    "    return series.astype(str).str.replace(pattern, '', regex=True).str.strip()\n",
    "\n",
    "def apply_custom_name_mapping(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['name'] = df['name'].map(mapping).fillna(df['name'])\n",
    "    return df\n",
    "\n",
    "def attach_isin_to_boursorama(b_df, e_df):\n",
    "    #Get unique (isin, name) mapping from Euronext\n",
    "    isin_name_map = get_unique_isin_name_combinations(e_df)\n",
    "\n",
    "    #Reset index in Boursorama to access 'name' as column\n",
    "    b_reset = b_df.reset_index()\n",
    "\n",
    "    #Merge on the pre-cleaned 'name'\n",
    "    merged = pd.merge(\n",
    "        b_reset,\n",
    "        isin_name_map,\n",
    "        on='name',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    unmatched_count = merged['isin'].isna().sum()\n",
    "    \n",
    "    if unmatched_count > 0:\n",
    "        print(f\"⚠️ {unmatched_count} rows had no matching ISIN.\")\n",
    "\n",
    "    return merged.set_index(['symbol', 'date'])\n",
    "\n",
    "def remove_inactive_stocks(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Step 1: Group by symbol and check if turnover is always zero\n",
    "    inactive_symbols = (\n",
    "        df.groupby('symbol')['turnover']\n",
    "        .apply(lambda x: (x == 0).all())\n",
    "    )\n",
    "    \n",
    "    # Step 2: Filter out those symbols\n",
    "    active_symbols = inactive_symbols[~inactive_symbols].index\n",
    "    \n",
    "    # Step 3: Keep only rows with active symbols\n",
    "    return df[df.index.get_level_values('symbol').isin(active_symbols)]\n",
    "\n",
    "def get_both(year):\n",
    "    suffix = ['westfield', 'mo.', 'ds', 'we', 'co', 'rpfd', 'sa', 'i', 'inc', 'tion', 'i18',\n",
    "            '(exassystembrime)', 'om.', 'i14', '(societe)','act.a','inv', 'htls', 'ds06',\n",
    "            'mo.', 'opr', 'opa', 'i13', 'cc', 'vilcc', 'i16', 'nv', 'se', '(ex:eurotunnel)',\n",
    "            'corp', 'ltd']\n",
    "    prefix = ['srd']\n",
    "    bourso_name_convert = {\n",
    "        \"bainsdemermona\": \"bainsmermona\",\n",
    "        \"baccaratn\":\"baccarat\",\n",
    "        \"bigbeninteractiv\":\"bigbeninteractive\",\n",
    "        \"bastideleconfor\":\"bastideleconfort\",\n",
    "        \"cambodgecien\":\"cambodgen\",\n",
    "        \"robertetcie87\":\"robertetc\",\n",
    "        \"robertetcdv\":\"robertet\",\n",
    "        \"casinoguichardperrachon\":\"casinoguichard\",\n",
    "        \"casinoguicper\":\"casinoguichard\",\n",
    "        \"sartoriussted\":\"sartoriusstedbio\",\n",
    "        \"sartoriusbiotech\":\"sartoriusstedbio\",\n",
    "        \"eurofinsscientif\":'eurofinsscient',\n",
    "        \"exelindustrie\":\"exelindustries\",\n",
    "        \"deltaplusgrp\":\"deltaplusgroup\",\n",
    "        \"dassaultsys\":\"dassaultsystemes\",\n",
    "        \"euroress\":\"euroressources\",\n",
    "        \"foncierelyonnais\":\"foncierelyonnaise\",\n",
    "        \"pernodricardnv11\":\"pernodricard\",\n",
    "        \"ramsaygenerale\":\"ramsaygensante\",\n",
    "        \"gecinanominatif\":\"gecinanom\",\n",
    "        \"gtt(gaztransportettec)\":\"gtt\",\n",
    "        \"idlogistics\":\"idlogisticsgroup\",\n",
    "        \"igeplusxao\":\"ige+xao\",\n",
    "        \"kering(ex:ppr)\":\"kering\",\n",
    "        \"lebonn\":\"lebon\",\n",
    "        \"linedata\":\"linedataservices\",\n",
    "        \"arcelormittal\":\"arcelor\",\n",
    "        \"malterfrancobel\":\"malteriesfcobel\",\n",
    "        \"maurel&prom\":\"maureletprom\",\n",
    "        \"maurelpr\":\"maureletprom\",\n",
    "        \"maurel\":\"maureletprom\",\n",
    "        \"michelinn\":\"michelin\",\n",
    "        \"michelin(mlnv)\":\"michelinnv20\",\n",
    "        \"metropoletele\":\"metropoletv\",\n",
    "        \"m6metropoletele\":\"metropoletv\",\n",
    "        \"nrjgrp\":\"nrjgroup\",\n",
    "        \"fiducialrealestate\":\"fiducialrealest\",\n",
    "        \"partouche\":\"groupepartouche\",\n",
    "        \"grpepartouche\":\"groupepartouche\",\n",
    "        \"patrimoinecom\":\"patrimoineetcomm\",\n",
    "        \"pharmagestinteract\":\"pharmagestinter\",\n",
    "        \"publicisgrp\":\"publicisgroupe\",\n",
    "        \"plastvaldeloire\":\"plastvalloire\",\n",
    "        \"plastivaloire\":\"plastvalloire\",\n",
    "        \"plastvdeloir\":\"plastvalloire\",\n",
    "        \"eurazeodaanf\":\"eurazeo\",\n",
    "        \"groupesteria\":\"soprasteriagroup\",\n",
    "        \"secheenviron\":\"secheenvironnem\",    \n",
    "        \"silic\":\"silc\",\n",
    "        \"soitecpsr16\":\"soitec\",\n",
    "        \"soprasteria\":\"soprasteriagroup\",\n",
    "        \"sqlinr\":\"sql\",\n",
    "        \"stmicroelectr\":\"stmicroelectronics\",\n",
    "        \"schneiderel\":\"schneiderelectric\",\n",
    "        \"schneiderelec\":\"schneiderelectric\",\n",
    "        \"technip\":\"technipfmc\",\n",
    "        \"thermador\":\"thermadorgroupe\",\n",
    "        \"tikehaurt170717\":\"tikehaucapital\",\n",
    "        \"technicolornr\":\"technicolor\",\n",
    "        \"pierreetvacances\":\"pierrevacances\",\n",
    "        \"veoliaenvironnem\":\"veoliaenviron\",\n",
    "        \"veolia\":\"veoliaenviron\",\n",
    "        \"viel\":\"vieletcompagnie\",\n",
    "        \"voltaliart080719\":\"voltalia\",\n",
    "        \"vrankenpommerymonopole\":\"vrankenpommery\",\n",
    "        \"xfabsilicon\":\"xfab\",\n",
    "        \"vrankenpommerymo\":\"vrankenpommery\"\n",
    "    }\n",
    "    #suffix_regex = ['i\\\\d*']\n",
    "\n",
    "    bourso = convert_bourso_daily(read_bourso_year(year))\n",
    "    bourso['name'] = remove_substrings(bourso['name'],[' ', '-', '.'])\n",
    "    bourso['name'] = remove_ending_substrings(bourso['name'],suffix)\n",
    "    bourso['name'] = remove_starting_substrings(bourso['name'],prefix)\n",
    "    bourso = apply_custom_name_mapping(bourso, bourso_name_convert)\n",
    "    #bourso['name'] = remove_ending_substrings_regex(bourso['name'],suffix_regex)\n",
    "\n",
    "    \n",
    "    euro = get_bourso_matching_df(read_euronext_year(year))\n",
    "    euro['name'] = remove_substrings(euro['name'],[' ', '-', '.'])\n",
    "    euro['name'] = remove_ending_substrings(euro['name'],suffix)\n",
    "    euro['name'] = remove_starting_substrings(euro['name'],prefix)\n",
    "    #euro['name'] = remove_ending_substrings_regex(euro['name'],suffix_regex)\n",
    "    euro.reset_index(inplace=True)\n",
    "    euro['date'] = euro['date'].apply(lambda x: dateutil.parser.parse(x))\n",
    "\n",
    "    euro.set_index('symbol', append=False, inplace=True)\n",
    "    euro.set_index('date', append=True, inplace=True)\n",
    "    euro.sort_index()\n",
    "    \n",
    "    bourso = attach_isin_to_boursorama(bourso, euro)\n",
    "\n",
    "    bourso = remove_inactive_stocks(bourso)\n",
    "    euro = remove_inactive_stocks(euro)\n",
    "    return bourso, euro\n",
    "\n",
    "b, e = get_both(\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
