{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import dateutil\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import requests\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p bourso/\n",
    "!rm -rf bourso/20*\n",
    "stream = requests.get('https://www.lrde.epita.fr/~ricou/pybd/projet/bourso.tgz', stream=True)\n",
    "tarfile.open(fileobj=stream.raw, mode='r|gz').extractall('bourso/') # try 'r:gz' if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>last</th>\n",
       "      <th>volume</th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020-09-15 11:11:02.091659</th>\n",
       "      <th>1rPMMT</th>\n",
       "      <td>11.600</td>\n",
       "      <td>9523</td>\n",
       "      <td>1rPMMT</td>\n",
       "      <td>m6 metropole tele.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1rPMMTNV</th>\n",
       "      <td>17.650</td>\n",
       "      <td>0</td>\n",
       "      <td>1rPMMTNV</td>\n",
       "      <td>metropole i15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020-11-06 12:51:02.049578</th>\n",
       "      <th>1rPMMT</th>\n",
       "      <td>10.120</td>\n",
       "      <td>35577</td>\n",
       "      <td>1rPMMT</td>\n",
       "      <td>m6 metropole tele.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1rPMMTNV</th>\n",
       "      <td>17.650</td>\n",
       "      <td>0</td>\n",
       "      <td>1rPMMTNV</td>\n",
       "      <td>metropole i15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-05 17:01:02.132038</th>\n",
       "      <th>1rPMMT</th>\n",
       "      <td>10.300</td>\n",
       "      <td>109171</td>\n",
       "      <td>1rPMMT</td>\n",
       "      <td>m6 metropole tele.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23 09:11:02.115775</th>\n",
       "      <th>1rPMMT</th>\n",
       "      <td>9.780</td>\n",
       "      <td>1245</td>\n",
       "      <td>1rPMMT</td>\n",
       "      <td>metropole tele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020-04-09 10:42:02.366142</th>\n",
       "      <th>1rPMMTNV</th>\n",
       "      <td>17.650</td>\n",
       "      <td>0</td>\n",
       "      <td>1rPMMTNV</td>\n",
       "      <td>metropole i15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1rPMMT</th>\n",
       "      <td>9.710</td>\n",
       "      <td>22596</td>\n",
       "      <td>1rPMMT</td>\n",
       "      <td>metropole tele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020-09-25 15:31:01.930607</th>\n",
       "      <th>1rPMMT</th>\n",
       "      <td>10.140</td>\n",
       "      <td>24491</td>\n",
       "      <td>1rPMMT</td>\n",
       "      <td>m6 metropole tele.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1rPMMTNV</th>\n",
       "      <td>17.650</td>\n",
       "      <td>0</td>\n",
       "      <td>1rPMMTNV</td>\n",
       "      <td>metropole i15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24834 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       last  volume    symbol  \\\n",
       "                           symbol                               \n",
       "2020-09-15 11:11:02.091659 1rPMMT    11.600    9523    1rPMMT   \n",
       "                           1rPMMTNV  17.650       0  1rPMMTNV   \n",
       "2020-11-06 12:51:02.049578 1rPMMT    10.120   35577    1rPMMT   \n",
       "                           1rPMMTNV  17.650       0  1rPMMTNV   \n",
       "2020-10-05 17:01:02.132038 1rPMMT    10.300  109171    1rPMMT   \n",
       "...                                     ...     ...       ...   \n",
       "2020-06-23 09:11:02.115775 1rPMMT     9.780    1245    1rPMMT   \n",
       "2020-04-09 10:42:02.366142 1rPMMTNV  17.650       0  1rPMMTNV   \n",
       "                           1rPMMT     9.710   22596    1rPMMT   \n",
       "2020-09-25 15:31:01.930607 1rPMMT    10.140   24491    1rPMMT   \n",
       "                           1rPMMTNV  17.650       0  1rPMMTNV   \n",
       "\n",
       "                                                   name  \n",
       "                           symbol                        \n",
       "2020-09-15 11:11:02.091659 1rPMMT    m6 metropole tele.  \n",
       "                           1rPMMTNV       metropole i15  \n",
       "2020-11-06 12:51:02.049578 1rPMMT    m6 metropole tele.  \n",
       "                           1rPMMTNV       metropole i15  \n",
       "2020-10-05 17:01:02.132038 1rPMMT    m6 metropole tele.  \n",
       "...                                                 ...  \n",
       "2020-06-23 09:11:02.115775 1rPMMT        metropole tele  \n",
       "2020-04-09 10:42:02.366142 1rPMMTNV       metropole i15  \n",
       "                           1rPMMT        metropole tele  \n",
       "2020-09-25 15:31:01.930607 1rPMMT    m6 metropole tele.  \n",
       "                           1rPMMTNV       metropole i15  \n",
       "\n",
       "[24834 rows x 4 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['name'] = tmp['name'].str.lower()\n",
    "tmp[tmp['name'].str.contains('metropole')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_last(df):\n",
    "    \"\"\" last is of object type and sometimes ends with (c) or (s)\"\"\"\n",
    "    return [float(re.split('\\\\(.\\\\)$',str(x))[0].replace(' ','').replace(',','.')) for x in df[\"last\"]]\n",
    "\n",
    "def read_bourso_year(year):\n",
    "    compA = pd.concat({dateutil.parser.parse(f.split('compA ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('bourso/' + year + '/compA*')})\n",
    "    compB = pd.concat({dateutil.parser.parse(f.split('compB ')[1].split('.bz2')[0]):pd.read_pickle(f) for f in glob.glob('bourso/' + year + '/compB*')})\n",
    "    merge = pd.concat([compA, compB])\n",
    "    merge['last'] = clean_last(merge)\n",
    "    merge.reset_index(level=1, drop=True, inplace=True)\n",
    "    merge.rename_axis('date', axis=0, inplace=True)\n",
    "    #dropping duplicates only checks columns\n",
    "    merge = merge.reset_index().drop_duplicates().set_index('date')\n",
    "    merge.set_index('symbol', append=True, inplace=True)\n",
    "    merge = merge.swaplevel(0,1).sort_index()\n",
    "    \n",
    "    #delta indicates the volume(number of stock sold) per entry instead of volume which is cumulative per day\n",
    "    merge['delta'] = np.zeros(len(merge))\n",
    "    for stock in merge.index.levels[0]:\n",
    "        merge.loc[(stock, slice(None)), 'delta'] =  merge.loc[(stock, slice(None)) ,'volume'].diff()\n",
    "    \n",
    "    #filling holes from start of day data and missing data\n",
    "    merge.loc[merge.delta < 0, 'delta'] = 0\n",
    "    merge.delta = merge.delta.fillna(0)\n",
    "\n",
    "    #sets the delta of the first entry to its volume instead of 0\n",
    "    #we should do this but it fails on 2020 and 2023 so it's disabled for now\n",
    "    #merge.loc[merge.groupby('symbol').head(1).index, 'delta'] = merge.groupby('symbol')['volume'].transform('first')\n",
    "\n",
    "    return merge\n",
    "\n",
    "#test = read_bourso_year('2020')\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bourso_daily(df):\n",
    "    df['turnover'] = df['last'] * df['delta']\n",
    "\n",
    "    dates = df.index.get_level_values('date').normalize()\n",
    "    dates.name = 'date'\n",
    "\n",
    "    df_daily = df.groupby(['symbol', dates]).agg({\n",
    "        'last': 'last',      # Last entry of the day\n",
    "        'volume': 'max',     # Maximum volume of the day\n",
    "        'name': 'first',     # First name entry of the day\n",
    "        'turnover': 'sum'    # Sum of all turnovers in that day\n",
    "    })\n",
    "    return df_daily\n",
    "\n",
    "#tmp = convert_bourso_daily(test)\n",
    "#tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euronext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p euronext/\n",
    "!rm -rf euronext/\n",
    "stream = requests.get('https://www.lrde.epita.fr/~ricou/pybd/projet/euronext.tgz', stream=True)\n",
    "tarfile.open(fileobj=stream.raw, mode='r|gz').extractall('euronext/') # try 'r:gz' if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting at some point in 2022 the column names were changed\n",
    "import dateutil.parser\n",
    "\n",
    "\n",
    "rename_dict = {\n",
    "    \"Open Price\": \"Open\",\n",
    "    \"High Price\": \"High\",\n",
    "    \"low Price\": \"Low\",\n",
    "    \"last Price\": \"Last\",\n",
    "    \"last Trade MIC Time\":\"Last Date/Time\",\n",
    "    \"Currency\":\"Trading Currency\"\n",
    "}\n",
    "\n",
    "#note that some entries in open, high, low, last are just set to -\n",
    "#ok apparently the currency can be set as 0\n",
    "\n",
    "def read_euronext_file(path):\n",
    "    if path.endswith(\".csv\"):\n",
    "        return pd.read_csv(path, delimiter='\\t')\n",
    "    return pd.read_excel(path)\n",
    "\n",
    "def regularize_data_to_numbers(df):\n",
    "    \"\"\" last is of object type and sometimes ends with (c) or (s)\"\"\"\n",
    "    df[['Volume','Turnover']] = df[['Volume','Turnover']].replace('-',0).fillna(0)\n",
    "    df['Last'] = [round(float(x),2) for x in df[\"Last\"]]\n",
    "    df['Volume'] = [int(x) for x in df[\"Volume\"]]\n",
    "    df['Turnover'] = [round(float(x),2) for x in df[\"Turnover\"]]\n",
    "    return df\n",
    "\n",
    "def regularize_euronext_empty_columns_fill(df):\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "    if 'Closing Price' in df.columns:\n",
    "        df['Last'] = df['Last'].fillna(df['Closing Price']).fillna(0)\n",
    "        df.drop(columns=['Closing Price'], inplace=True)\n",
    "    if 'Closing Price DateTime' in df.columns:\n",
    "        df['Last Date/Time'] = df['Last Date/Time'].fillna(df['Closing Price DateTime']).fillna(0)\n",
    "        df.drop(columns=['Closing Price DateTime'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def regularize_data_to_string(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_euronext_year(year):\n",
    "    eur = pd.concat([regularize_euronext_empty_columns_fill(read_euronext_file(f)) for f in glob.glob('euronext/*' + year + '*')])\n",
    "    #the first three rows are a preamble that doesnt give us anything\n",
    "    eur = eur.iloc[3:].reset_index(drop=True)\n",
    "    eur = eur[~((eur['Last'] == '-') & (eur['Volume'] == '-') & (eur['Turnover'] == '-'))]\n",
    "    eur = eur[~((eur['Symbol'].isna()))]\n",
    "    #any remaining '-' in the data we assume to be null or 0\n",
    "    eur = regularize_data_to_numbers(eur)\n",
    "    eur = eur.drop_duplicates()\n",
    "    return eur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_553684/300960938.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[['Volume','Turnover']] = df[['Volume','Turnover']].replace('-',0).fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Market</th>\n",
       "      <th>Trading Currency</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Last Date/Time</th>\n",
       "      <th>Time Zone</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000MERCIS</td>\n",
       "      <td>FR0010285965</td>\n",
       "      <td>ALMIL</td>\n",
       "      <td>Euronext Growth Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>30</td>\n",
       "      <td>30.2</td>\n",
       "      <td>29</td>\n",
       "      <td>30.00</td>\n",
       "      <td>17/05/2023 17:35</td>\n",
       "      <td>CET</td>\n",
       "      <td>343</td>\n",
       "      <td>10109.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CRSI</td>\n",
       "      <td>FR0013341781</td>\n",
       "      <td>AL2SI</td>\n",
       "      <td>Euronext Growth Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.575</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.57</td>\n",
       "      <td>17/05/2023 17:25</td>\n",
       "      <td>CET</td>\n",
       "      <td>3597</td>\n",
       "      <td>5636.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.S.T. GROUPE</td>\n",
       "      <td>FR0000076887</td>\n",
       "      <td>ALAST</td>\n",
       "      <td>Euronext Growth Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>17/05/2023 16:26</td>\n",
       "      <td>CET</td>\n",
       "      <td>10698</td>\n",
       "      <td>16227.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AB SCIENCE</td>\n",
       "      <td>FR0010557264</td>\n",
       "      <td>AB</td>\n",
       "      <td>Euronext Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.34</td>\n",
       "      <td>17/05/2023 17:38</td>\n",
       "      <td>CET</td>\n",
       "      <td>252916</td>\n",
       "      <td>1065494.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC ARBITRAGE</td>\n",
       "      <td>FR0004040608</td>\n",
       "      <td>ABCA</td>\n",
       "      <td>Euronext Paris</td>\n",
       "      <td>EUR</td>\n",
       "      <td>6.05</td>\n",
       "      <td>6.08</td>\n",
       "      <td>6.03</td>\n",
       "      <td>6.05</td>\n",
       "      <td>17/05/2023 17:35</td>\n",
       "      <td>CET</td>\n",
       "      <td>17478</td>\n",
       "      <td>105742.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name          ISIN Symbol                 Market Trading Currency  \\\n",
       "0     1000MERCIS  FR0010285965  ALMIL  Euronext Growth Paris              EUR   \n",
       "1          2CRSI  FR0013341781  AL2SI  Euronext Growth Paris              EUR   \n",
       "2  A.S.T. GROUPE  FR0000076887  ALAST  Euronext Growth Paris              EUR   \n",
       "3     AB SCIENCE  FR0010557264     AB         Euronext Paris              EUR   \n",
       "4  ABC ARBITRAGE  FR0004040608   ABCA         Euronext Paris              EUR   \n",
       "\n",
       "   Open   High   Low   Last    Last Date/Time Time Zone  Volume    Turnover  \n",
       "0    30   30.2    29  30.00  17/05/2023 17:35       CET     343    10109.80  \n",
       "1  1.57  1.575  1.54   1.57  17/05/2023 17:25       CET    3597     5636.90  \n",
       "2  1.54   1.54   1.5   1.50  17/05/2023 16:26       CET   10698    16227.36  \n",
       "3   4.3   4.37  4.02   4.34  17/05/2023 17:38       CET  252916  1065494.05  \n",
       "4  6.05   6.08  6.03   6.05  17/05/2023 17:35       CET   17478   105742.85  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eur = read_euronext_year('2023')\n",
    "eur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note Hammerson plc and t stamp inc is in gbp and usd respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different markets for the same stock?\n",
    "# - markets are not in the boursorama data so i assume we can just ignore that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that volume in euronext is equivalent to delta in bourso\n",
    "def get_bourso_matching_df(euronext_df):\n",
    "    tmp = euronext_df[['Symbol', 'Last Date/Time', 'ISIN', 'Last', 'Volume', 'Name', 'Turnover']]\n",
    "    tmp = tmp.rename(columns={'Symbol':'symbol', 'Last Date/Time':'date', 'ISIN':'isin', 'Last':'last', 'Volume':'volume', 'Name':'name', 'Turnover':'turnover'})\n",
    "    tmp = tmp.set_index(['symbol','date'])\n",
    "    tmp = tmp.sort_index()\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusing Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in boursorama the name is 'AIR FRANCE -KLM' and in euronext it's 'AIR FRANCE - KLM' so i'm just going to remove all of the spaces so we can match up the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_isin_name_combinations(df):\n",
    "    cleaned = df.copy()\n",
    "    cleaned['isin'] = cleaned['isin'].astype(str).str.strip()\n",
    "    cleaned['name'] = cleaned['name'].astype(str).str.strip().str.lower()\n",
    "    return cleaned[['isin', 'name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "def remove_substrings(series: pd.Series, substrings: list[str]) -> pd.Series:\n",
    "    cleaned = series.astype(str)\n",
    "    for sub in substrings:\n",
    "        cleaned = cleaned.str.replace(sub, '', regex=False)\n",
    "    return cleaned.str.lower()\n",
    "\n",
    "def remove_ending_substrings(series: pd.Series, endings: list[str]) -> pd.Series:\n",
    "    cleaned = series.astype(str)\n",
    "    for ending in endings:\n",
    "        cleaned = cleaned.str.rstrip()  # In case of trailing spaces before matching\n",
    "        cleaned = cleaned.apply(lambda x: x[:-len(ending)] if x.endswith(ending) else x)\n",
    "    return cleaned.str.strip()\n",
    "\n",
    "def remove_starting_substrings(series: pd.Series, prefixes: list[str]) -> pd.Series:\n",
    "    cleaned = series.astype(str)\n",
    "    for prefix in prefixes:\n",
    "        cleaned = cleaned.str.lstrip()  # In case of leading spaces before matching\n",
    "        cleaned = cleaned.apply(lambda x: x[len(prefix):] if x.startswith(prefix) else x)\n",
    "    return cleaned.str.strip()\n",
    "\n",
    "def remove_ending_substrings_regex(series: pd.Series, endings: list[str]) -> pd.Series:\n",
    "    # Escape any special regex characters in endings to match them literally\n",
    "    escaped_endings = [re.escape(e) for e in endings]\n",
    "    \n",
    "    # Build one regex pattern that matches any ending at the end of a string ($)\n",
    "    pattern = f\"({'|'.join(escaped_endings)})$\"\n",
    "    \n",
    "    # Use str.replace with regex=True to remove matching suffixes\n",
    "    return series.astype(str).str.replace(pattern, '', regex=True).str.strip()\n",
    "\n",
    "def apply_custom_name_mapping(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['name'] = df['name'].map(mapping).fillna(df['name'])\n",
    "    return df\n",
    "\n",
    "def get_fusion(year):\n",
    "    suffix = ['westfield', 'mo.', 'ds', 'we', 'co', 'rpfd', 'sa', 'i', 'inc', 'tion', 'i18',\n",
    "            '(exassystembrime)', 'om.', 'i14', '(societe)','act.a','inv', 'htls', 'ds06',\n",
    "            'mo.', 'opr', 'opa', 'i13', 'cc', 'vilcc', 'i16', 'nv', 'se', '(ex:eurotunnel)',\n",
    "            'corp', 'ltd']\n",
    "    prefix = ['srd']\n",
    "    bourso_name_convert = {\n",
    "        \"bainsdemermona\": \"bainsmermona\",\n",
    "        \"baccaratn\":\"baccarat\",\n",
    "        \"bigbeninteractiv\":\"bigbeninteractive\",\n",
    "        \"bastideleconfor\":\"bastideleconfort\",\n",
    "        \"cambodgecien\":\"cambodgen\",\n",
    "        \"robertetcie87\":\"robertetc\",\n",
    "        \"robertetcdv\":\"robertet\",\n",
    "        \"casinoguichardperrachon\":\"casinoguichard\",\n",
    "        \"casinoguicper\":\"casinoguichard\",\n",
    "        \"sartoriussted\":\"sartoriusstedbio\",\n",
    "        \"sartoriusbiotech\":\"sartoriusstedbio\",\n",
    "        \"eurofinsscientif\":'eurofinsscient',\n",
    "        \"exelindustrie\":\"exelindustries\",\n",
    "        \"deltaplusgrp\":\"deltaplusgroup\",\n",
    "        \"dassaultsys\":\"dassaultsystemes\",\n",
    "        \"euroress\":\"euroressources\",\n",
    "        \"foncierelyonnais\":\"foncierelyonnaise\",\n",
    "        \"pernodricardnv11\":\"pernodricard\",\n",
    "        \"ramsaygenerale\":\"ramsaygensante\",\n",
    "        \"gecinanominatif\":\"gecinanom\",\n",
    "        \"gtt(gaztransportettec)\":\"gtt\",\n",
    "        \"idlogistics\":\"idlogisticsgroup\",\n",
    "        \"igeplusxao\":\"ige+xao\",\n",
    "        \"kering(ex:ppr)\":\"kering\",\n",
    "        \"lebonn\":\"lebon\",\n",
    "        \"linedata\":\"linedataservices\",\n",
    "        \"arcelormittal\":\"arcelor\",\n",
    "        \"malterfrancobel\":\"malteriesfcobel\",\n",
    "        \"maurel&prom\":\"maureletprom\",\n",
    "        \"maurelpr\":\"maureletprom\",\n",
    "        \"maurel\":\"maureletprom\",\n",
    "        \"michelinn\":\"michelin\",\n",
    "        \"michelin(mlnv)\":\"michelinnv20\",\n",
    "        \"metropoletele\":\"metropoletv\",\n",
    "        \"m6metropoletele\":\"metropoletv\",\n",
    "        \"nrjgrp\":\"nrjgroup\",\n",
    "        \"fiducialrealestate\":\"fiducialrealest\",\n",
    "        \"partouche\":\"groupepartouche\",\n",
    "        \"grpepartouche\":\"groupepartouche\",\n",
    "        \"patrimoinecom\":\"patrimoineetcomm\",\n",
    "        \"pharmagestinteract\":\"pharmagestinter\",\n",
    "        \"publicisgrp\":\"publicisgroupe\",\n",
    "        \"plastvaldeloire\":\"plastvalloire\",\n",
    "        \"plastivaloire\":\"plastvalloire\",\n",
    "        \"plastvdeloir\":\"plastvalloire\",\n",
    "        \"eurazeodaanf\":\"eurazeo\",\n",
    "        \"groupesteria\":\"soprasteriagroup\",\n",
    "        \"secheenviron\":\"secheenvironnem\",    \n",
    "        \"silic\":\"silc\",\n",
    "        \"soitecpsr16\":\"soitec\",\n",
    "        \"soprasteria\":\"soprasteriagroup\",\n",
    "        \"sqlinr\":\"sql\",\n",
    "        \"stmicroelectr\":\"stmicroelectronics\",\n",
    "        \"schneiderel\":\"schneiderelectric\",\n",
    "        \"schneiderelec\":\"schneiderelectric\",\n",
    "        \"technip\":\"technipfmc\",\n",
    "        \"thermador\":\"thermadorgroupe\",\n",
    "        \"tikehaurt170717\":\"tikehaucapital\",\n",
    "        \"technicolornr\":\"technicolor\",\n",
    "        \"pierreetvacances\":\"pierrevacances\",\n",
    "        \"veoliaenvironnem\":\"veoliaenviron\",\n",
    "        \"veolia\":\"veoliaenviron\",\n",
    "        \"viel\":\"vieletcompagnie\",\n",
    "        \"voltaliart080719\":\"voltalia\",\n",
    "        \"vrankenpommerymonopole\":\"vrankenpommery\",\n",
    "        \"xfabsilicon\":\"xfab\",\n",
    "        \"vrankenpommerymo\":\"vrankenpommery\"\n",
    "    }\n",
    "    euro_name_convert = {\n",
    "        \"\":\"\"\n",
    "    }\n",
    "    #suffix_regex = ['i\\\\d*']\n",
    "\n",
    "    bourso = convert_bourso_daily(read_bourso_year(year))\n",
    "    bourso['name'] = remove_substrings(bourso['name'],[' ', '-', '.'])\n",
    "    bourso['name'] = remove_ending_substrings(bourso['name'],suffix)\n",
    "    bourso['name'] = remove_starting_substrings(bourso['name'],prefix)\n",
    "    bourso = apply_custom_name_mapping(bourso, bourso_name_convert)\n",
    "    #bourso['name'] = remove_ending_substrings_regex(bourso['name'],suffix_regex)\n",
    "\n",
    "    \n",
    "    euro = get_bourso_matching_df(read_euronext_year(year))\n",
    "    euro['name'] = remove_substrings(euro['name'],[' ', '-', '.'])\n",
    "    euro['name'] = remove_ending_substrings(euro['name'],suffix)\n",
    "    euro['name'] = remove_starting_substrings(euro['name'],prefix)\n",
    "    #euro['name'] = remove_ending_substrings_regex(euro['name'],suffix_regex)\n",
    "    euro.reset_index(inplace=True)\n",
    "    euro['date'] = euro['date'].apply(lambda x: dateutil.parser.parse(x))\n",
    "\n",
    "    euro.set_index('symbol', append=False, inplace=True)\n",
    "    euro.set_index('date', append=True, inplace=True)\n",
    "    euro.sort_index()\n",
    "    return bourso, euro\n",
    "\n",
    "b, e = get_fusion(\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 55485 rows had no matching ISIN.\n"
     ]
    }
   ],
   "source": [
    "def attach_isin_to_boursorama(b_df, e_df):\n",
    "    # Step 1: Get unique (isin, name) mapping from Euronext\n",
    "    isin_name_map = get_unique_isin_name_combinations(e_df)\n",
    "\n",
    "    # Step 2: Reset index in Boursorama to access 'name' as column\n",
    "    b_reset = b_df.reset_index()\n",
    "\n",
    "    # Step 3: Merge on the pre-cleaned 'name'\n",
    "    merged = pd.merge(\n",
    "        b_reset,\n",
    "        isin_name_map,\n",
    "        on='name',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    unmatched_count = merged['isin'].isna().sum()\n",
    "    \n",
    "    if unmatched_count > 0:\n",
    "        print(f\"⚠️ {unmatched_count} rows had no matching ISIN.\")\n",
    "\n",
    "    return merged.set_index(['symbol', 'date'])\n",
    "\n",
    "copy_b = attach_isin_to_boursorama(b, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    }
   ],
   "source": [
    "print(len(copy_b['name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sfrgroup', 'segro(reit)', 'siph', 'bailinvestissementfonciere',\n",
       "       'selogercom', 'sodiceexpansion', 'sucrierepithiviers',\n",
       "       'skisrossignol', 'fonc6&7emeparisn', 'salvepar', 'salveparpsr14',\n",
       "       'silice12ope', 'etamdeveloppement', 'tesfran', 'terreis',\n",
       "       'francoisfreres', 'transgrts270619', 'banquetarneaud', 'uffbanque',\n",
       "       'valespadr', 'valespadrpfda', 'vectrane', 'vermandoisesucr',\n",
       "       'provim', 'vmmateriaux', 'eurosos55%sep23ex', 'eurosicosrjun21ex',\n",
       "       'salveporn01jan22ex', 'zodiacaero', 'zodiacaeroe17'], dtype=object)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_isin = copy_b[copy_b['isin'].isna()]['name'].unique()\n",
    "print(len(no_isin))\n",
    "no_isin[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
